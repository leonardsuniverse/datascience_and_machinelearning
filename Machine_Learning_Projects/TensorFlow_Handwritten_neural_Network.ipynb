{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9963ea8-c60a-4383-830e-d00d91dc1330",
   "metadata": {},
   "source": [
    "__How to Create a Neural Network for Handwritten Digit Recognition Using TensorFlow__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392e1f7-cb22-4297-9214-c638db4028b8",
   "metadata": {},
   "source": [
    "Neural networks are computational models inspired by the human brain's structure and function. They are used in machine learning and artificial intelligence to recognize patterns, make decisions, and solve complex problems. Here's a detailed breakdown of neural networks:\n",
    "\n",
    "__Basic Concepts__\n",
    "\n",
    "1. __Neurons:__\n",
    "   - The basic units of neural networks, analogous to neurons in the brain.\n",
    "   - Each neuron receives one or more inputs, processes them, and outputs a result.\n",
    "\n",
    "2. __Layers:__\n",
    "   - __Input Layer:__ The first layer that receives the initial data (e.g., pixel values of an image).\n",
    "   - __Hidden Layers:__ Intermediate layers that perform various transformations and computations on the input data.\n",
    "   - __Output Layer:__ The final layer that produces the network's output (e.g., classifying an image as a digit from 0 to 9).\n",
    "\n",
    "3. __Weights and Biases:__\n",
    "   - __Weights:__ Parameters that adjust the input's importance in the neuronâ€™s computation.\n",
    "   - __Biases:__ Additional parameters that adjust the output along with the weights.\n",
    "\n",
    "4. __Activation Functions:__\n",
    "   - Functions that introduce non-linearity into the network, enabling it to learn complex patterns.\n",
    "   - Common activation functions include ReLU (Rectified Linear Unit), sigmoid, and tanh.\n",
    "\n",
    "__How Neural Networks Work:__\n",
    "\n",
    "1. __Forward Propagation:__\n",
    "   - Data is passed from the input layer through the hidden layers to the output layer.\n",
    "   - Each neuron computes a weighted sum of its inputs, adds a bias, and applies an activation function to produce its output.\n",
    "\n",
    "2. __Loss Function:__\n",
    "   - A function that measures the difference between the network's predictions and the actual target values.\n",
    "   - Common loss functions include Mean Squared Error (MSE) for regression and Cross-Entropy Loss for classification.\n",
    "\n",
    "3. __Backward Propagation:__\n",
    "   - The process of adjusting the network's weights and biases to minimize the loss function.\n",
    "   - Uses algorithms like gradient descent to update the parameters in the direction that reduces the error.\n",
    "\n",
    "__Types of Neural Networks:__\n",
    "\n",
    "1. __Feedforward Neural Networks:__\n",
    "   - The simplest type where connections between the nodes do not form cycles.\n",
    "   - Typically used for tasks like image classification and regression.\n",
    "\n",
    "2. __Convolutional Neural Networks (CNNs):__\n",
    "   - Specialized for processing grid-like data such as images.\n",
    "   - Uses convolutional layers to automatically and adaptively learn spatial hierarchies of features.\n",
    "\n",
    "3. __Recurrent Neural Networks (RNNs):__\n",
    "   - Designed for sequential data processing, such as time series or natural language.\n",
    "   - Has connections that form directed cycles, allowing information to persist.\n",
    "\n",
    "4. __Generative Adversarial Networks (GANs):__\n",
    "   - Consists of two networks (a generator and a discriminator) that compete against each other to generate new, synthetic data samples.\n",
    "\n",
    "__Applications:__\n",
    "\n",
    "- __Image and Speech Recognition:__ Identifying objects in images or transcribing spoken words to text.\n",
    "- __Natural Language Processing:__ Tasks like sentiment analysis, language translation, and chatbots.\n",
    "- __Autonomous Vehicles:__ Enabling self-driving cars to recognize and react to their environment.\n",
    "- __Healthcare:__ Assisting in diagnosing diseases and personalizing treatments based on patient data.\n",
    "\n",
    "Neural networks have revolutionized many fields by enabling computers to perform complex tasks with high accuracy. As research and technology continue to advance, their capabilities and applications are expanding rapidly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f44a19-2a83-4ec5-8846-dc9d4e6f71aa",
   "metadata": {},
   "source": [
    "In this guide, I will implement a small subsection of object recognition digit recognition. Using TensorFlow, an open source Python library developed by the Google Brain for deep learning research, I will take hand-drawn images of the numbers 0-9 and build and train a neural network to recognize and predict the correct label for the digit displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3cff71-dd23-46fa-aa38-8c297a908821",
   "metadata": {},
   "source": [
    "__Importing the MNIST Dataset__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace28fe3-b928-4594-9c53-f9987e6b7140",
   "metadata": {},
   "source": [
    "The dataset I will be using in this guide is called the __MNIST__ dataset, and it is a classic in the machine learning community. This dataset is made up of images of handwritten digits, 28*28 pixels in size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad2989-e225-4fb6-a294-4fbac03b332a",
   "metadata": {},
   "source": [
    "I'll create a Python program to work with this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "817497ef-e712-43e0-a5fd-25f1226ec08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 55000\n",
      "Number of validation examples: 5000\n",
      "Number of test examples: 10000\n",
      "Train - Image shape: (32, 28, 28, 1), Label shape: (32,)\n",
      "Validation - Image shape: (32, 28, 28, 1), Label shape: (32,)\n",
      "Test - Image shape: (32, 28, 28, 1), Label shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load your MNIST data\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Reshape images to add a channel dimension (required for some models)\n",
    "train_images = train_images[..., np.newaxis]\n",
    "test_images = test_images[..., np.newaxis]\n",
    "\n",
    "# Define the number of examples for each dataset\n",
    "n_train = 55000\n",
    "n_validation = 5000\n",
    "n_test = 10000  # MNIST test set has 10,000 examples\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=n_validation, train_size=n_train, stratify=train_labels\n",
    ")\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(n_train).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "validation_dataset = validation_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Print the number of examples in each set\n",
    "print(f\"Number of training examples: {n_train}\")\n",
    "print(f\"Number of validation examples: {n_validation}\")\n",
    "print(f\"Number of test examples: {n_test}\")\n",
    "\n",
    "# Print dataset shapes to verify\n",
    "for image, label in train_dataset.take(1):\n",
    "    print(f\"Train - Image shape: {image.shape}, Label shape: {label.shape}\")\n",
    "\n",
    "for image, label in validation_dataset.take(1):\n",
    "    print(f\"Validation - Image shape: {image.shape}, Label shape: {label.shape}\")\n",
    "\n",
    "for image, label in test_dataset.take(1):\n",
    "    print(f\"Test - Image shape: {image.shape}, Label shape: {label.shape}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ebb251-fbb5-4e75-ad2f-a767318cdc3d",
   "metadata": {},
   "source": [
    "When reading in the data, we are using one-hot encoding to represent the labels (the actual digit drawn, e.g. \"3\") of the images. One hot encoding uses a vector of binary values to represent numeric or categorical values. As our labels are for the digits 0-9, the vector contains ten values, one for each possible digit. One of these values is set to 1, to represent the digit at that index of the vector, and the rest are set to 0. For example, the digit 3 is represented using the vector [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]. As the value at index 3 is stored as 1, the vector therefore represents the digit 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25149c07-5590-4f32-bae4-9a7d58308480",
   "metadata": {},
   "source": [
    "To represent the actual images themselves, the 28*28 pixels are flattened into a 1D vector which is 784 pixels in size. Each of the 784 pixels making up the image is stored as a value between 0 and 255. This determines the grayscale of the pixel, as our images are presented in black and white only. So a black pixel is represented by 255, and a white pixel by 0, with the various shades of gray somewhere in between."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe161a-0a30-4a2b-b32f-876f0ec49240",
   "metadata": {},
   "source": [
    "We can use the __mnist__ variable to find out the size of the dataset we have just imported. Looking at the __num_examples__ for each of the three subsets, we can determine that the dataset has been split into 55,000 images for training, 5000 for validation, and 10,000 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e5e4d-1d56-4530-823a-c8334972d383",
   "metadata": {},
   "source": [
    "Now that we have our data imported, it's time to think about the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84e04c-6b6e-48e3-bda9-fa63fb9a8a93",
   "metadata": {},
   "source": [
    "__Defining the Neural Network Architecture__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb3029-4824-4edd-9b90-70294088d692",
   "metadata": {},
   "source": [
    "The architecture of the neural network refers to elements such as the number of layers in the network, the number of units in each layer, and how the units are connected between layers. As neural networks are loosely inspired by the workings of the human brain, here the term unit is used to represent what we would biologically think of as a neuron. Like neurons passing signals around the brain, units take some values from previous units as input, perform a computation, and then pass on the new value as output to other units. These units are layered to form the network, starting at a minimum with one layer to output values. The term hidden layer is used for all of the layers in between the input and output layers, i.e. those \"hidden\" from the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861dbf71-1569-4a94-bbc3-fbd9fd0f21b4",
   "metadata": {},
   "source": [
    "Different architectures can yield dramatically different results, as the performance can be thought of as a function of the architecture among other things, such as the parameters, the data, and the duration of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f4187-1397-4d01-86b8-3bd1f0beffee",
   "metadata": {},
   "source": [
    "Adding the following lines of code to my file to store the number of units per layer in global variables. This allows us to alter the network architecture in one place, and at the end of the guide we can test for ourself how different numbers of layers and units will impact the results of our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff181dc3-934a-4b6a-a9e5-aae73036db4d",
   "metadata": {},
   "source": [
    "__Define the architecture:__\n",
    "\n",
    "Input layer: 784 neurons (28x28 pixels, flattened).\n",
    "First hidden layer: 512 neurons.\n",
    "Second hidden layer: 256 neurons.\n",
    "Third hidden layer: 128 neurons.\n",
    "Output layer: 10 neurons (for the 10 digit classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d983f77-ba9c-464d-b1b6-4160a485a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784  # input layer (28x28 pixels)\n",
    "n_hidden1 = 512  # 1st hidden layer\n",
    "n_hidden2 = 256  # 2nd hidden layer\n",
    "n_hidden3 = 128  # 3rd hidden layer\n",
    "n_output = 10  # output layer (0-9 digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14988593-f899-4597-a284-be0676616ae2",
   "metadata": {},
   "source": [
    "The term \"deep neural network\" relates to the number of hidden layers, with \"shallow\" usually meaning just one hidden layers, and \"deep\" referring to multiple hidden layers. Given enough training data, a shallow neural network with a sufficient number of units should theoretically be able to represent any function that a deep neural network can. But it is more computationally efficient to use a smaller deep neural network to achieve the same task that would require a shallow network with exponentially more hidden units. Shallow neural networks also often encounter overfitting, where the network essentially memorizes the training data that it has seen, and not able to generalize the knowledge to new data. This is why deep neural networks are more commonly used: the multiple layers between the raw input data and the ouput label allow the network to learn features at various levels of abstraction, making the network itself better able to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524ed6a-277f-409a-bc1b-b0653dc331e5",
   "metadata": {},
   "source": [
    "Other elements of the neural network that need to be defined here are the hyperparameters. Unlike the parameters that will get updated during training, these values are set initially and remain constant throughout the process. I will add the following variables and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7285235-dea2-4fa1-b15c-52781de96a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "n_iterations = 1000\n",
    "batch_size = 128\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5fc179-9236-41d6-8259-26f6762265ff",
   "metadata": {},
   "source": [
    "The learning rate represents how much the parameters will adjust at each step of the learning process. These adjustments are a key component of training: after each pass through the network we tune the weights slightly to try and reduce the loss. Larger learning rates can converge faster, but also have the potential to overshoot the optimal values as they are updated. The number of iterations refers to how many times we go through the training step, and the batch size refers to how many training examples we are using at each step. The __dropout__ variable represents a threshold at which we eliminate some units at random. We will be using __dropout__ in our final hidden layer to give each unit a 50% chance of being eliminated at every training step. This helps prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1b725-dda7-4cb1-a10e-7543ed0a329a",
   "metadata": {},
   "source": [
    "I have defined the architecture of our neural network, and the hyperparameters that impact the learning process. The next step is to build the network as a TensorFlow graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5848f-fa50-4fba-b722-14490963f579",
   "metadata": {},
   "source": [
    "__Building the TensorFlow Graph__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8f4ba-cc4c-4acd-ba0a-a66c0d54a64f",
   "metadata": {},
   "source": [
    "To build our network, we will set up the network as a computational graph for TensorFlow to execute. The core concept of TensorFlow is the tensor, a data structure similar to an array or list, which are initialized, manipulated as they are passed through the graph, and updated through the learning process. I'll start by defining three tensors as placeholders, which are tensors that we'll feed values into later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90869cbe-80e6-4123-8798-c646ccb5f4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the input and output dimensions\n",
    "n_input = 784  # Example input dimension (e.g., for MNIST dataset)\n",
    "n_output = 10  # Example output dimension (e.g., for 10 classes in MNIST)\n",
    "n_hidden1 = 256 # Number of neurons in the first hidden layer\n",
    "n_hidden2 = 128 # Number of neurons in the second hidden layer\n",
    "n_hidden3 = 64 # Number of neurons in the third hidden layer\n",
    "\n",
    "# Define the input layer\n",
    "inputs = tf.keras.Input(shape=(n_input,))\n",
    "\n",
    "# Define a dense layer\n",
    "dense_output = tf.keras.layers.Dense(n_output, activation='softmax')(inputs)\n",
    "\n",
    "# Define a dropout layer\n",
    "dropout_output = tf.keras.layers.Dropout(rate=0.5)(dense_output)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=dropout_output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a70e3-47fe-4aa8-93b4-7e475db3605f",
   "metadata": {},
   "source": [
    "The only parameter that needs to be specified at its declaration is the size of the data we will be feeding in. For X we use a shape of [None, 784], where None represents any amount, as we will be feeding in an undefined number of 784 pixel images. The shape of Y is [None, 10] as we will be using it for an undefined number of label outputs, with 10 possible classes. The __keep_prob__ tensor is used to control the dropout rate, and we initialize it as a placeholder rather than an immutable variable because we want to use the same tensor both for training (when __dropout__ is set to 0.5) and testing (when__dropout is set to 1.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5448d5-956c-44d8-be17-b30e1545d539",
   "metadata": {},
   "source": [
    "The parameters that the network will update in the training process are the __weight__ and __bias__ values, so for these we need to set an initial value rather than an empty placeholder. These values are essentially where the network does its learning, as they are used in the activation functions of the neurons, representing the strength of the connections between units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ed762-8124-4301-bdd7-fcf34d8f51b7",
   "metadata": {},
   "source": [
    "Since the values are optimized during training, we could set them to zero for now. But the initial value actually has a siginificant impact on the final accuracy of the model. We'll use random values from a truncated normal distribution for the weights. We want them to be close to zero, so they can adjust in either a positive or negative direction, and slighlty different, so they generate different errors. This will ensure that the model learns something useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b46dd15-6972-4503-b7b9-5cde519e4e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: <tf.Variable 'Variable:0' shape=(784, 256) dtype=float32, numpy=\n",
      "array([[ 0.10912701, -0.06028754, -0.08777511, ...,  0.16331856,\n",
      "         0.02426625, -0.14737217],\n",
      "       [ 0.08802983,  0.01761909,  0.00662895, ...,  0.06846601,\n",
      "         0.03951794, -0.00520563],\n",
      "       [ 0.06956836, -0.09908468,  0.07674159, ...,  0.10094736,\n",
      "        -0.08234289, -0.09580178],\n",
      "       ...,\n",
      "       [-0.0915952 , -0.03328989, -0.12329942, ..., -0.09815805,\n",
      "        -0.03031763,  0.04160902],\n",
      "       [-0.06959183, -0.00157581,  0.0276113 , ..., -0.03845313,\n",
      "        -0.02102679, -0.03816045],\n",
      "       [ 0.02080665,  0.12605421, -0.03502177, ..., -0.04341035,\n",
      "        -0.05843858, -0.03363249]], dtype=float32)>\n",
      "w2: <tf.Variable 'Variable:0' shape=(256, 128) dtype=float32, numpy=\n",
      "array([[ 7.9279914e-02,  2.6675394e-02, -7.4648432e-02, ...,\n",
      "        -8.3644018e-03, -1.4972430e-01,  6.9708094e-02],\n",
      "       [ 1.1843636e-01, -8.3254322e-02,  1.7807755e-01, ...,\n",
      "        -1.3897742e-01, -3.5175565e-04, -2.0673510e-02],\n",
      "       [ 1.7969014e-01, -4.9825944e-02,  4.1269367e-03, ...,\n",
      "        -6.6361792e-02, -6.5987505e-02,  1.9880909e-01],\n",
      "       ...,\n",
      "       [-3.1171290e-02,  1.0388496e-01, -9.4931398e-05, ...,\n",
      "        -3.1012518e-02,  6.2046344e-03,  6.6749088e-02],\n",
      "       [ 4.0957101e-02,  9.0444289e-02, -8.1558852e-03, ...,\n",
      "         3.4773316e-02, -4.0901363e-02,  6.5394789e-02],\n",
      "       [-2.7310161e-03,  1.5377291e-01, -4.2677123e-02, ...,\n",
      "        -4.4632025e-02,  8.5576087e-02, -8.5766293e-02]], dtype=float32)>\n",
      "w3: <tf.Variable 'Variable:0' shape=(128, 64) dtype=float32, numpy=\n",
      "array([[-0.03083473,  0.03527905,  0.04055462, ...,  0.0843473 ,\n",
      "        -0.06517123,  0.07937341],\n",
      "       [ 0.08409126, -0.0325679 ,  0.07527166, ...,  0.00726068,\n",
      "        -0.00985684, -0.02442545],\n",
      "       [ 0.04871152, -0.08990247, -0.08543427, ...,  0.00142325,\n",
      "         0.06450047,  0.09777202],\n",
      "       ...,\n",
      "       [ 0.12493589, -0.00537623,  0.13996764, ...,  0.04179041,\n",
      "         0.02442196,  0.15063024],\n",
      "       [-0.1909179 ,  0.08482232, -0.00353338, ...,  0.04456342,\n",
      "         0.05669193,  0.04814649],\n",
      "       [ 0.04998594, -0.00161132, -0.10616274, ...,  0.13302766,\n",
      "        -0.1460313 ,  0.09670078]], dtype=float32)>\n",
      "out: <tf.Variable 'Variable:0' shape=(64, 10) dtype=float32, numpy=\n",
      "array([[-0.07080697, -0.04935046,  0.16922   , -0.07877716, -0.00790189,\n",
      "         0.08642532,  0.07384764,  0.1039798 , -0.02702836,  0.08744384],\n",
      "       [-0.04236989, -0.17441922, -0.17015144,  0.13437532, -0.10424441,\n",
      "         0.13209015,  0.19786684, -0.12006272,  0.07100382, -0.01859676],\n",
      "       [-0.03044572, -0.04645824, -0.13729383, -0.05223141,  0.13141052,\n",
      "        -0.18520498, -0.03181877, -0.09436241,  0.06358438,  0.02403764],\n",
      "       [ 0.02460755, -0.0205199 , -0.11246544,  0.10136785,  0.11307617,\n",
      "        -0.19840907, -0.02424835, -0.05194268, -0.0018871 , -0.11044776],\n",
      "       [-0.09492276,  0.08569328,  0.05265683, -0.17421739,  0.06001156,\n",
      "         0.07630148,  0.06406342, -0.03988211,  0.07703239, -0.07157759],\n",
      "       [ 0.05311609, -0.01777345, -0.07886841, -0.09514008, -0.04269622,\n",
      "         0.06691404, -0.00797413,  0.03068492, -0.10500234,  0.02621599],\n",
      "       [ 0.00164272,  0.02411861, -0.03989984, -0.10140596, -0.19820608,\n",
      "         0.08288118,  0.02495983, -0.01414552, -0.08446022, -0.12169842],\n",
      "       [-0.09104725, -0.02195947, -0.15421864,  0.14164406, -0.19738425,\n",
      "         0.10083219, -0.05262346,  0.0365044 , -0.1150378 , -0.02112619],\n",
      "       [-0.14660816, -0.09895458,  0.15779826, -0.04349604, -0.02726448,\n",
      "         0.02042029,  0.10337253,  0.15123264,  0.01780869,  0.0300312 ],\n",
      "       [-0.04297983,  0.06841736,  0.06898528,  0.16270947, -0.14710121,\n",
      "        -0.18325745,  0.06302226, -0.06465315, -0.19734263,  0.13286327],\n",
      "       [ 0.00511426, -0.11052241, -0.01982057, -0.00827597, -0.03357075,\n",
      "        -0.06064569,  0.00400375, -0.162682  ,  0.00289954,  0.04994596],\n",
      "       [-0.02937078,  0.01170255,  0.11580131, -0.01331042, -0.01023732,\n",
      "         0.01850011, -0.11455401, -0.03597084,  0.08817684,  0.1411908 ],\n",
      "       [-0.09832741, -0.00111008,  0.13126238, -0.00458779, -0.08710841,\n",
      "         0.19555591,  0.10215211, -0.11164401, -0.01662551,  0.00506359],\n",
      "       [ 0.07875877, -0.05658646,  0.13756645,  0.19720411,  0.01512528,\n",
      "         0.03862966, -0.02409321, -0.04080527, -0.03048579,  0.17719555],\n",
      "       [ 0.07971311, -0.12876122, -0.00313629,  0.02614646,  0.12830155,\n",
      "        -0.07480524,  0.04813303,  0.02804108,  0.04763205, -0.0704555 ],\n",
      "       [ 0.0654142 ,  0.1343674 , -0.05366381,  0.07032692,  0.12119659,\n",
      "         0.00340989,  0.10617669, -0.04705318, -0.01990402,  0.19455993],\n",
      "       [ 0.03911114,  0.01838998,  0.0810413 , -0.18900348,  0.02941195,\n",
      "        -0.05765733, -0.06891773,  0.06269793,  0.05036838, -0.00822692],\n",
      "       [-0.09422684,  0.00025975, -0.07488939, -0.07132586,  0.09708496,\n",
      "        -0.1687691 ,  0.05401776, -0.11221967,  0.09851398, -0.04759399],\n",
      "       [ 0.19566874,  0.07870142, -0.0307965 ,  0.04784304, -0.01190036,\n",
      "        -0.18819024,  0.11431432,  0.0686077 , -0.07984058,  0.04973208],\n",
      "       [-0.12628353,  0.03010588, -0.12110048, -0.17110357, -0.06920081,\n",
      "         0.02837545,  0.06780887, -0.16814029, -0.11966207, -0.06062537],\n",
      "       [-0.00137959,  0.10287596,  0.13260265, -0.10632509, -0.09961642,\n",
      "        -0.04675144, -0.18448858, -0.15571056, -0.18563347,  0.0949498 ],\n",
      "       [ 0.02671005, -0.01821019, -0.08041324, -0.00860597, -0.14461017,\n",
      "         0.02887603, -0.03207951,  0.1335005 , -0.15385687, -0.10213017],\n",
      "       [ 0.06403296,  0.01668524,  0.04668289,  0.1198561 , -0.03443384,\n",
      "        -0.06676109,  0.06198061,  0.13813776,  0.11552212, -0.06513482],\n",
      "       [-0.1529079 , -0.06140834, -0.00400362,  0.09412216, -0.06808653,\n",
      "         0.07782546, -0.00940718, -0.06185222, -0.10181161,  0.10820502],\n",
      "       [ 0.06211378,  0.08489376,  0.08929578,  0.03784305,  0.00218053,\n",
      "        -0.17968456,  0.16650344, -0.0358451 , -0.03994541,  0.1210845 ],\n",
      "       [-0.15050809, -0.00904876, -0.03524708, -0.08221518, -0.04663147,\n",
      "        -0.07943471, -0.17781202,  0.07610204, -0.03691962,  0.16167551],\n",
      "       [ 0.03489559,  0.04289442, -0.02331477,  0.09230583,  0.1254282 ,\n",
      "        -0.09522548, -0.04757051,  0.07758722,  0.10810091,  0.07088035],\n",
      "       [-0.01468173, -0.05779365, -0.04723987,  0.05198401, -0.04224004,\n",
      "         0.02157239,  0.00858587,  0.02421652, -0.08452735,  0.09912843],\n",
      "       [-0.131873  , -0.0617603 , -0.10140335, -0.14145483, -0.02420161,\n",
      "         0.06408288,  0.03691508,  0.09435136, -0.05665717, -0.06674977],\n",
      "       [ 0.11473981, -0.15707235, -0.00691384, -0.09916682,  0.04090064,\n",
      "         0.02789052, -0.03500087, -0.02237851, -0.06184234,  0.14201653],\n",
      "       [ 0.02013914,  0.02408949, -0.00254191, -0.04468777,  0.02742743,\n",
      "         0.04059036, -0.00294751, -0.05268919, -0.02871509,  0.19039674],\n",
      "       [-0.12614387, -0.07303472,  0.1132849 , -0.15680473, -0.10704961,\n",
      "         0.12103118, -0.12069499, -0.01165598,  0.09598153, -0.06749482],\n",
      "       [-0.18842356,  0.01938841, -0.02987945,  0.0504141 , -0.00680035,\n",
      "        -0.12466943,  0.13860025, -0.12623146, -0.02730612,  0.10827818],\n",
      "       [ 0.03123679, -0.07486392, -0.05701559, -0.04572162, -0.01759089,\n",
      "        -0.01159517,  0.03649414,  0.01317581,  0.05994605, -0.09585654],\n",
      "       [-0.11886405,  0.06475157, -0.00706755,  0.00232171,  0.08204194,\n",
      "         0.00246356,  0.02066572,  0.08334284,  0.06977069,  0.05201984],\n",
      "       [ 0.0551277 , -0.0148757 ,  0.01475883, -0.10642983, -0.02200703,\n",
      "        -0.11319174,  0.05883953,  0.11989679,  0.0605968 , -0.06413734],\n",
      "       [ 0.00807043, -0.15587637,  0.01154753,  0.08229665,  0.08587368,\n",
      "         0.08449851, -0.06564452, -0.12224275, -0.05491742, -0.00390615],\n",
      "       [ 0.18865411,  0.05502792, -0.02112146, -0.03293738,  0.13948704,\n",
      "        -0.16762549,  0.00905643,  0.00973364,  0.09921905, -0.01726299],\n",
      "       [-0.10150591, -0.07924021,  0.08139887,  0.08377176, -0.04380586,\n",
      "        -0.13271299, -0.01222658,  0.05550262, -0.00056335,  0.09945706],\n",
      "       [ 0.12365185,  0.10803741,  0.17463976, -0.02696041,  0.03634369,\n",
      "         0.04676742, -0.01260027,  0.17190805, -0.04395592, -0.01316534],\n",
      "       [-0.0431333 ,  0.01172316,  0.03689902, -0.10259884, -0.02471952,\n",
      "        -0.06957003,  0.08706918, -0.18573608,  0.10627846, -0.11539274],\n",
      "       [-0.08719502, -0.00054954, -0.00816861,  0.06990862,  0.05191203,\n",
      "        -0.00672692,  0.01136294,  0.107734  , -0.03768935, -0.10559372],\n",
      "       [-0.1556763 , -0.01592697,  0.11589366,  0.19436906, -0.09205531,\n",
      "         0.02801106, -0.0128198 , -0.18250827, -0.10201194,  0.06136725],\n",
      "       [ 0.04420486,  0.05671201,  0.12923342,  0.09776241, -0.06394089,\n",
      "        -0.18682133,  0.19931734,  0.07708282,  0.1089903 , -0.01923863],\n",
      "       [ 0.07776517, -0.0103707 ,  0.0507691 ,  0.11893096,  0.08798927,\n",
      "        -0.18267947,  0.03183449,  0.05438858,  0.06713711,  0.0577719 ],\n",
      "       [-0.1215478 ,  0.01823402,  0.07425673,  0.06363862, -0.08204945,\n",
      "        -0.1608713 ,  0.03674563, -0.02981965, -0.10013675,  0.00976374],\n",
      "       [ 0.00935616,  0.01996327,  0.0542013 , -0.01468456, -0.12018286,\n",
      "        -0.16245823,  0.00288965, -0.08781417, -0.0630094 , -0.03884321],\n",
      "       [-0.05448682,  0.02452545,  0.02549135, -0.03325986,  0.01862266,\n",
      "        -0.06240275,  0.00198895,  0.01887382,  0.06915035,  0.08787245],\n",
      "       [-0.18624672,  0.11384922, -0.17572425,  0.1746889 , -0.1332892 ,\n",
      "        -0.00804051, -0.04995413,  0.03162252,  0.16235651,  0.1126877 ],\n",
      "       [-0.134347  ,  0.02699131,  0.16111179, -0.05453177,  0.01080954,\n",
      "        -0.09660953,  0.02548612, -0.0257227 ,  0.07755239,  0.0143717 ],\n",
      "       [ 0.04553724,  0.01508964, -0.07373672, -0.09076843,  0.14924836,\n",
      "        -0.01678686, -0.06181204, -0.06475732, -0.08870305, -0.01419725],\n",
      "       [ 0.05134255,  0.11148957, -0.13504016, -0.12884031,  0.02087804,\n",
      "         0.02314485,  0.05244764,  0.07743843,  0.11470941,  0.03779456],\n",
      "       [-0.11209916,  0.10500374, -0.03376518, -0.04231942,  0.05529667,\n",
      "        -0.03384579, -0.0034345 , -0.02281226, -0.09501489, -0.044124  ],\n",
      "       [ 0.00124115,  0.01468598, -0.07858337,  0.09855717, -0.04917528,\n",
      "        -0.17417437,  0.01176356,  0.10627275,  0.13529624, -0.04790564],\n",
      "       [ 0.1437126 ,  0.16135798, -0.13426457, -0.1329187 ,  0.06520658,\n",
      "        -0.05978858, -0.07232846, -0.04877582, -0.18172105,  0.05324686],\n",
      "       [ 0.05392178, -0.11668686,  0.07482076, -0.04055188,  0.00477283,\n",
      "         0.17760298, -0.04222526,  0.09965944, -0.14216377,  0.05933526],\n",
      "       [ 0.11444267,  0.06518925,  0.0733432 , -0.01702429,  0.0197039 ,\n",
      "        -0.04343861, -0.15189965, -0.07530486, -0.08495768,  0.00733328],\n",
      "       [-0.16743727, -0.19535051,  0.03984934, -0.06147189, -0.07630971,\n",
      "         0.00964904, -0.01631343,  0.11466028,  0.05763523, -0.18658851],\n",
      "       [ 0.00392467,  0.0565661 ,  0.10705944, -0.04899629,  0.05240731,\n",
      "        -0.03474346,  0.1688392 , -0.01647357, -0.04777215, -0.04585817],\n",
      "       [-0.00591024, -0.12897573, -0.08747656, -0.08560435,  0.06108024,\n",
      "         0.06453032, -0.18390666, -0.06384566, -0.14279823, -0.11750143],\n",
      "       [-0.0691581 , -0.0544607 , -0.04751806,  0.15456374,  0.0012293 ,\n",
      "         0.07469603,  0.02306342,  0.07224128, -0.19541451, -0.05933144],\n",
      "       [ 0.08169983,  0.11115351,  0.11041509, -0.0260279 , -0.16745518,\n",
      "        -0.0221114 ,  0.14357966,  0.04318485,  0.0289341 , -0.05865436],\n",
      "       [ 0.04925322,  0.00077799,  0.04111587,  0.06779151, -0.06472978,\n",
      "         0.11121532, -0.08726969, -0.01400079, -0.00288735, -0.04120795],\n",
      "       [ 0.09759189,  0.07921517,  0.01539143,  0.12873562, -0.00265038,\n",
      "        -0.00721952, -0.1032875 , -0.04388341,  0.01317288, -0.02192289]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'w1': tf.Variable(tf.random.truncated_normal ([n_input, n_hidden1], stddev=0.1)),\n",
    "    'w2': tf.Variable(tf.random.truncated_normal ([n_hidden1, n_hidden2], stddev=0.1)),\n",
    "    'w3': tf.Variable(tf.random.truncated_normal ([n_hidden2, n_hidden3], stddev=0.1)),\n",
    "    'out': tf.Variable(tf.random.truncated_normal ([n_hidden3, n_output], stddev=0.1))\n",
    "}\n",
    "\n",
    "# Print the weights to verify (optional)\n",
    "for key, value in weights.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e14faca-7d14-48ed-b6e5-bce15a2540e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
    "    'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
    "    'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7775fb-eb88-4638-b1a7-ecfbc210ab47",
   "metadata": {},
   "source": [
    "Next, I will set up the layers of the network by defining the operations that will manipulate the tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a30313a6-0de1-4085-b8b2-ac17494aae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(784, 256) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.math.add), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(256,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(256, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.math.add_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(128,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(128, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.math.add_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(64, 10) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.math.add_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(10,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "# Define placeholders for input data and dropout probability\n",
    "X = tf.keras.Input(shape=(n_input,))\n",
    "\n",
    "# Define the neural network layers\n",
    "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "\n",
    "layer_drop = layers.Dropout(rate=0.5)(layer_3)\n",
    "output_layer = tf.add(tf.matmul(layer_drop, weights['out']), biases['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb08da-e5f9-458a-b588-c8b6a4bb7fc7",
   "metadata": {},
   "source": [
    "The only parameter that needs to be specified at its declaration is the size of the data we will be feeding in. For X we use a shape of [None, 784], where None represents any amount, as we will be feeding in an undefined number of 784-pixel images. The shape of Y is [None, 10] as we will be using it for an undefined number of label ouputs, with 10 possible classes. The __dropout__ is set to 0.5 for training and 1.0 for testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b0e8f-688b-44c6-b1e6-58225a661217",
   "metadata": {},
   "source": [
    "The parameters that the network will update in the training process are the __weight__ and __bias__ values, so for these we need to set an initial value rather than an empty placeholder. These values are essentially where the network does its learning, as they are used in the activation functions of the neurons, representing the strength of connections between units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021252ac-86e6-4fd4-aa36-8eb0875da237",
   "metadata": {},
   "source": [
    "Since the values are optimized during training, we could set them to zero for now. But the initial value actually has a significant impact on the final accuracy of the model. We'll use random values from a truncated normal disribution for the weights. We want them to be close to zero, so they can adjust in either a positive or negative direction, and slightly different, so they generate different errors. This will ensure that the model learns something useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e65e6e9-06ac-4f64-8a9c-288b5f0012af",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1': tf.Variable(tf.random.truncated_normal([n_input, n_hidden1], stddev=0.1)),\n",
    "    'w2': tf.Variable(tf.random.truncated_normal([n_hidden1, n_hidden2], stddev=0.1)),\n",
    "    'w3': tf.Variable(tf.random.truncated_normal([n_hidden2, n_hidden3], stddev=0.1)),\n",
    "    'out': tf.Variable(tf.random.truncated_normal([n_hidden3, n_output], stddev=0.1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd6256-d248-4866-96c7-0624b4b79b2a",
   "metadata": {},
   "source": [
    "For the bias, we use a small constant value to ensure that the tensors activate in the initial stages and therefore contribute to the propagation. The weights and bias tensors are stored in dictionary objects for ease of access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f8aa466-cce5-4171-92f9-5c442ac60cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
    "    'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
    "    'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f17ae-b0c8-4d7d-9aec-03c43c82a3ae",
   "metadata": {},
   "source": [
    "Next, set up the layers of the network by defining the operations that will manipulate the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53150901-b4ce-4f46-9a93-8c9356f6dc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(784, 256) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.math.add_4), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(256,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(256, 128) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.math.add_5), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(128,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(128, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.math.add_6), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.linalg.matmul_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(64, 10) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.math.add_7), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'Variable:0' shape=(10,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    }
   ],
   "source": [
    "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "layer_drop = layers.Dropout(rate=0.5)(layer_3)\n",
    "output_layer = tf.add(tf.matmul(layer_drop, weights['out']), biases['out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef2768-6981-4d1b-8f07-356bd9242d98",
   "metadata": {},
   "source": [
    "Each hidden layer will execute matrix multiplication on the previous layer's outputs and the current layer's weights, and add the bias to these values. At the last hidden layer, we will apply a dropout operation using our value of 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4afd216-0a55-490c-a39e-5b38c77f3c22",
   "metadata": {},
   "source": [
    "The final step in building the graph is to define the loss function that we want to optimize. A poplular choice of loss function in TensorFlow programs is cross-entropy, also known as log-loss, which quantifies the difference between two probability distributions (the predictions and the labels). A perfect classification would result in a cross-entropy of 0, with the loss completely minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9eca46-95dc-4e18-a243-090da248b4cd",
   "metadata": {},
   "source": [
    "We also need to choose the optimization algorithm which will be used to minimize the loss function. A process named gradient descent optimization is a common method for finding the (local) minimum of a function by taking iterative steps along the gradient in a negative (descending) direction.There are several choices of gradient decsent optimization algorithms already implemented in TensofFlow, and this guide we will be using the __Adam Optimizer__. This extends upon gradient descent optimization by using momentum to speed up the process through computing an exponentially weighted average of the gradients and using that in the adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0d6ecd5-986a-48f3-8dc9-69239ef586c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Complile the model\n",
    "from tensorflow.keras import layers, optimizers\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03477b-b766-424c-b4cf-e2a32c091ce8",
   "metadata": {},
   "source": [
    "We've now defined the network and built it out with TensoFlow. The next step is to feed the data through the graph to train it, and then test that it has actually learnt something."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa93920-9f42-4a84-931f-2ae5a84af124",
   "metadata": {},
   "source": [
    "The training process involves feeding the training dataset through the graph and optimizing the loss function. Every time the network iterates through a batch of more training images, it updates the parameters to reduce the loss in order to more accurately predict the digits shown. The testing process involves running our testing dataset through the trained graph, and keeping track of the number of images that are correctly predicted, so that we can calculate the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8687f8a-5692-4681-a59c-f00027778a00",
   "metadata": {},
   "source": [
    "Before starting the training process, we will define our method of evaluating the accuracy so we can print it out on mini-batches of data while we train. These printed statements will allow us to check that from the first iteration to the last, loss decreases and accuracy increases; they will also allow us to track whether or not we have ran enough iterations to reach a consistent and optimal result:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40062a06-ba0b-4ff6-8914-0349a4b4f771",
   "metadata": {},
   "source": [
    "In __correct_pred__, we use the __arg_max__ function to compare which images are being predicted correctly by looking at the __output_layer__ (predictions) and Y (labels), and we use the __equal__ function to return this as a list of __Booleans__. We can then cast this list to floats and calculate the mean to get a total accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d2da2-bdf7-443d-864e-495577344ba3",
   "metadata": {},
   "source": [
    "We are now ready to initialize a session for running the graph. In this session we will feed the network with our training examples, and once trained, we feed the same graph with new test examples to determine the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10e8903e-e648-42c9-9678-d69571a4a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "600/600 [==============================] - 11s 17ms/step - loss: 2.3137 - accuracy: 0.0989 - val_loss: 2.3037 - val_accuracy: 0.1005\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 12s 19ms/step - loss: 2.3035 - accuracy: 0.1023 - val_loss: 2.3028 - val_accuracy: 0.0975\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 2.3026 - accuracy: 0.1030 - val_loss: 2.3030 - val_accuracy: 0.1001\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 2.3023 - accuracy: 0.1045 - val_loss: 2.3027 - val_accuracy: 0.0998\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 2.3021 - accuracy: 0.1045 - val_loss: 2.3029 - val_accuracy: 0.1003\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 2.3022 - accuracy: 0.1058 - val_loss: 2.3028 - val_accuracy: 0.1022\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 9s 15ms/step - loss: 2.3015 - accuracy: 0.1071 - val_loss: 2.3032 - val_accuracy: 0.1001\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 2.3017 - accuracy: 0.1054 - val_loss: 2.3035 - val_accuracy: 0.0975\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 9s 16ms/step - loss: 2.3016 - accuracy: 0.1074 - val_loss: 2.3035 - val_accuracy: 0.0942\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 2.3006 - accuracy: 0.1098 - val_loss: 2.3038 - val_accuracy: 0.0929\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 2.3038 - accuracy: 0.0929\n",
      "Test Accuracy: 0.0929\n",
      "Accuracy calculated using TensorFlow operations: 0.0929\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# Define the dimensions of each layer\n",
    "n_input = 784       # Example input size, like for MNIST dataset (28x28 images)\n",
    "n_hidden1 = 256     # Example size of the first hidden layer\n",
    "n_hidden2 = 128     # Example size of the second hidden layer\n",
    "n_hidden3 = 64      # Example size of the third hidden layer\n",
    "n_output = 10       # Example output size, like for MNIST dataset (10 classes)\n",
    "\n",
    "# Define the neural network model using Keras Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(n_input,)),\n",
    "    layers.Dense(n_hidden1, activation='relu', kernel_initializer=tf.initializers.TruncatedNormal(stddev=0.1)),\n",
    "    layers.Dense(n_hidden2, activation='relu', kernel_initializer=tf.initializers.TruncatedNormal(stddev=0.1)),\n",
    "    layers.Dense(n_hidden3, activation='relu', kernel_initializer=tf.initializers.TruncatedNormal(stddev=0.1)),\n",
    "    layers.Dropout(rate=0.5),\n",
    "    layers.Dense(n_output, activation='softmax', kernel_initializer=tf.initializers.TruncatedNormal(stddev=0.1))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Example data for training (replace with actual data)\n",
    "# Note: Ensure your data is preprocessed and ready for training\n",
    "# train_X: Training features\n",
    "# train_Y: Training labels (one-hot encoded)\n",
    "# test_X: Testing features\n",
    "# test_Y: Testing labels (one-hot encoded)\n",
    "# Replace these lines with actual data loading\n",
    "train_X = np.random.rand(60000, n_input)  # Replace with actual training features\n",
    "train_Y = to_categorical(np.random.randint(0, n_output, 60000), n_output)  # Replace with actual training labels\n",
    "test_X = np.random.rand(10000, n_input)  # Replace with actual testing features\n",
    "test_Y = to_categorical(np.random.randint(0, n_output, 10000), n_output)  # Replace with actual testing labels\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# Fit the model on the training data\n",
    "history = model.fit(train_X, train_Y, epochs=num_epochs, batch_size=batch_size, validation_data=(test_X, test_Y))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(test_X, test_Y)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Making predictions and calculating accuracy\n",
    "predictions = model.predict(test_X)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(test_Y, axis=1)\n",
    "\n",
    "# Calculate accuracy using TensorFlow operations\n",
    "correct_pred = tf.equal(predicted_classes, true_classes)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "print(f'Accuracy calculated using TensorFlow operations: {accuracy.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d7d17-2b3f-4a0b-b112-1504dc5fada0",
   "metadata": {},
   "source": [
    "The essence of the training process in deep learning is to optimize the loss function. Here we are aiming to minimize the difference between the predicted labels of the images, and the true label of the images. The process involves four steps which are repeated for a set number of iterations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9cbfd-20c5-4828-8d6d-b9faecbd9b27",
   "metadata": {},
   "source": [
    "- Propagate values forward through the network\n",
    "- Compute the loss\n",
    "- Propagate values backward through the network\n",
    "- Update the parameters\n",
    "At each training step, the parameters are adjusted slightly to try and reduce the loss for the next step. As the learning progresses, we should see a reduction in loss, and eventually we can stop training and use the network as a model for testing our new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d371fa-b49c-480f-9531-c05ef7738be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "600/600 [==============================] - 12s 16ms/step - loss: 1.1059 - accuracy: 0.6581 - val_loss: 0.3841 - val_accuracy: 0.9041\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.4641 - accuracy: 0.8694 - val_loss: 0.2637 - val_accuracy: 0.9236\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.3546 - accuracy: 0.9014 - val_loss: 0.2149 - val_accuracy: 0.9364\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.2912 - accuracy: 0.9198 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 10s 17ms/step - loss: 0.2501 - accuracy: 0.9311 - val_loss: 0.1625 - val_accuracy: 0.9521\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.2224 - accuracy: 0.9390 - val_loss: 0.1501 - val_accuracy: 0.9543\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.1968 - accuracy: 0.9465 - val_loss: 0.1382 - val_accuracy: 0.9585\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.1777 - accuracy: 0.9520 - val_loss: 0.1276 - val_accuracy: 0.9604\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 11s 18ms/step - loss: 0.1606 - accuracy: 0.9565 - val_loss: 0.1186 - val_accuracy: 0.9629\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 10s 16ms/step - loss: 0.1490 - accuracy: 0.9585 - val_loss: 0.1116 - val_accuracy: 0.9654\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1116 - accuracy: 0.9654\n",
      "\n",
      "Test accuracy: 0.9654\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "batch_size = 100\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(60000).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)\n",
    "\n",
    "# Define the neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', kernel_initializer=tf.initializers.TruncatedNormal(stddev=0.1)),\n",
    "    layers.Dense(128, activation='relu', kernel_initializer=tf.initializers.TruncatedNormal(stddev=0.1)),\n",
    "    layers.Dense(64, activation='relu', kernel_initializer=tf.initializers.TruncatedNormal(stddev=0.1)),\n",
    "    layers.Dropout(rate=0.5),\n",
    "    layers.Dense(10, activation='softmax', kernel_initializer=tf.initializers.TruncatedNormal(stddev=0.1))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = optimizers.Adam(learning_rate=1e-4)\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss_object, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=test_dataset)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f'\\nTest accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1fb3d4-4f2f-42ca-851a-6472d6f603a2",
   "metadata": {},
   "source": [
    "To try and improve the accuracy of our model, or to learn more about the impact of tuning hyperparameters, we can test the effect of changing the learning rate, the dropout threshold, the batch size, and the number of iterations. We can also change the number of units in our hidden layers, and change the amount of hidden layers themselves, to see how different architectures increase or decrease the model accuracy. To dempnstrate that the network is actually recognizing the hand-drawn images, let's test it on a single image of our own. I will be using  a sample image downloaded from curl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c84a689d-6da5-4508-9608-514cebae3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image verified successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "file_path = 'test_img.png'\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        img.verify()  # Verify the image\n",
    "        print(\"Image verified successfully.\")\n",
    "    # Reopen the image to display it\n",
    "    img = Image.open(file_path)\n",
    "    img.show()  # This will display the image if you have an image viewer available\n",
    "except (IOError, SyntaxError) as e:\n",
    "    print('Cannot identify image file:', e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d55fd0d-5c06-4c5d-8381-0d705a366802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processed successfully.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "file_path = 'test_img.png'\n",
    "\n",
    "try:\n",
    "    # Open the image and convert to grayscale\n",
    "    img = Image.open(file_path).convert('L')\n",
    "    \n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Flatten the array\n",
    "    img_flat = img_array.ravel()\n",
    "    \n",
    "    # Invert the flattened array\n",
    "    img_inverted = np.invert(img_flat)\n",
    "    \n",
    "    print(\"Image processed successfully.\")\n",
    "    # If you need to see the result as an image\n",
    "    img_inverted_reshaped = img_inverted.reshape(img_array.shape)\n",
    "    inverted_image = Image.fromarray(img_inverted_reshaped)\n",
    "    inverted_image.show()\n",
    "except Exception as e:\n",
    "    print('Error processing image:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46521e1b-3860-4f8a-9bb8-ae382778c1da",
   "metadata": {},
   "source": [
    "The __open__ function of the __Image__ library loads the test image as a 4D array containing the three RGB color channels and the Alpha transparency. This is not the same representation we used previously when reading in the dataset with TensorFlow, so we'll need to do some extra work to match the format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913fd0e1-5716-4240-992e-01b1d388a184",
   "metadata": {},
   "source": [
    "First, we use the __convert__ function with the __L__ parameter to reduce the 4D RGBA representation to one grayscale color channel. We store this as a __numpy__ array and invert it using __np.invert__, because the current matrix represents black as 0 and white as 255, whereas we need the opposite. Finally we call __ravel__ to flatten the array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0730071-b504-43ae-b628-523691fd1932",
   "metadata": {},
   "source": [
    "Now that the image is structured correctly, we can run a session in the same way as previously, but this time only feeding in the single image for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f2b63d-3dd5-4438-b1ab-715973a687d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test image: 3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the image\n",
    "file_path = 'test_img.png'\n",
    "img = Image.open(file_path).convert('L')  # Convert to grayscale\n",
    "img = img.resize((28, 28))  # Resize to 28x28 if necessary\n",
    "img = np.array(img)  # Convert to NumPy array\n",
    "img = img / 255.0  # Normalize the image\n",
    "img = img.reshape((1, 28 * 28))  # Flatten the image and add batch dimension\n",
    "\n",
    "# Load the model (ensure the model variable is defined and loaded properly)\n",
    "# model = ... (Load your model here, e.g., using tf.keras.models.load_model)\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict(img)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Prediction for test image:\", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d0edb-0ac5-4c2e-81c5-3683b0b9ba27",
   "metadata": {},
   "source": [
    "__Conclusion__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd73d5a-dccd-4e0b-b4ea-ce8d1ab92ca9",
   "metadata": {},
   "source": [
    "Neural networks, particularly CNNs, have revolutionized the field of handwritten digit recognition. They offer high accuracy, robustness, and adaptability, making them the method of choice for this task. The success of neural networks on the MNIST dataset has not only provided a benchmark for evaluating new algorithms but has also spurred advancements in deep learning techniques applied to a wide array of image recognition tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c21654-5df7-436f-b2fb-b2791e8563e5",
   "metadata": {},
   "source": [
    "__Future Directions__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949bf2d-83c9-40a0-b8ce-56c071e16282",
   "metadata": {},
   "source": [
    "1. Continued Improvement: Research continues to improve the accuracy and efficiency of neural networks, leveraging newer architectures and optimization techniques.\n",
    "2. Transfer Learning: Applying pretrained models on larger datasets to handwritten digit recognition can further enhance performance.\n",
    "3. Application Expansion: Extending these techniques to more complex datasets and real-world applications, such as recognizing handwritten text in natural scenes, remains an active area of development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d839d5a-b462-4b22-a7ee-ca64a0fe653e",
   "metadata": {},
   "source": [
    "In summary, neural networks have set a high standard in handwritten digit recognition, demonstrating their powerful capabilities and laying the groundwork for further innovations in the field of image recognition and beyond."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
